{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.查看服务器GPU等硬件信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.缓存云盘上的模型和数据集到服务器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetList: ['flowers17_tsycnh.zip', 'CCF_2019.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# 云盘的路径\n",
    "Cloud_Data_Path='/content/gdrive/MyDrive/DataSets/'\n",
    "Data_Set_Name='CCF_2019.zip' #数据集\n",
    "Cloud_Model_Path='/content/gdrive/MyDrive/Models/pytorchmodels/FinBERT_L-12_H-768_A-12/' #模型\n",
    "\n",
    "# 服务器的路径\n",
    "Local_Data_Path='/content/LocalDataSets/'\n",
    "Local_Model_Path='/content/LocalModels/'\n",
    "\n",
    "# 解压缩\n",
    "def unzip(file_path,tar_path):\n",
    "\n",
    "    # 压缩文件判断\n",
    "    if os.path.splitext(file_path)[-1]=='.zip':\n",
    "\n",
    "        zFile = zipfile.ZipFile(file_path, \"r\")\n",
    "        for files in zFile.namelist(): \n",
    "            zFile.extract(files,tar_path)\n",
    "        \n",
    "        zFile.close()\n",
    "\n",
    "# 下载到服务器\n",
    "def down_data():\n",
    "\n",
    "    # 列出云盘所有数据集\n",
    "    DataSetList=os.listdir(Cloud_Data_Path)   \n",
    "    print('DataSetList:',DataSetList)\n",
    "\n",
    "    # 下载数据集\n",
    "    if Data_Set_Name in DataSetList:\n",
    "        \n",
    "        # 创建本地数据集文件夹\n",
    "        if not os.path.exists(Local_Data_Path):\n",
    "            os.makedirs(Local_Data_Path)\n",
    "        \n",
    "        # 复制到本地\n",
    "        shutil.copy(Cloud_Data_Path+Data_Set_Name,Local_Data_Path+Data_Set_Name)\n",
    "\n",
    "        # 如果是压缩文件\n",
    "        unzip(Local_Data_Path+Data_Set_Name,Local_Data_Path)\n",
    "    \n",
    "    # 下载模型\n",
    "    try:\n",
    "        shutil.copytree(Cloud_Model_Path,Local_Model_Path+str(Cloud_Model_Path).split('/')[-2])\n",
    "    except FileExistsError as e:\n",
    "        pass\n",
    "    \n",
    "\n",
    "down_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.在服务器上安装环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.在预训练模型上进行微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  可视化\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "log_writer = SummaryWriter()\n",
    "\n",
    "run_path=''\n",
    "%tensorboard --logdir=/Users/mac/PycharmProjects/pythonProject/saved/runs/{run_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#-------------------- 模型和数据集路径 --------------------#\n",
    "model_path = '/content/LocalModels/FinBERT_L-12_H-768_A-12/'\n",
    "dataset_path = '/content/LocalDataSets/CCF_2019/'\n",
    "saved_path = '/content/gdrive/MyDrive/Saved_Models/FinBERT_L-12_H-768_A-12/'\n",
    "if not os.path.exists(saved_path):\n",
    "    os.makedirs(saved_path)\n",
    "\n",
    "# 读取数据\n",
    "\n",
    "\n",
    "def read_data(base_url):\n",
    "    return load_dataset('csv',\n",
    "                        data_files={'train': base_url + 'train.csv',\n",
    "                                    'test': base_url + 'test.csv',\n",
    "                                    'dev': base_url + 'dev.csv'})\n",
    "\n",
    "\n",
    "# 编码训练集\n",
    "def tokenize_data(tokenizer: BertTokenizer, word_length: int = 32):\n",
    "    # 加载数据集\n",
    "    raw_datasets = read_data(dataset_path)\n",
    "\n",
    "    # 向量化函数\n",
    "    def tokenize_function(dataset):\n",
    "        return tokenizer(dataset['title'], truncation=True, padding='max_length', max_length=word_length)\n",
    "\n",
    "    tokenized_datasets = raw_datasets.map(tokenize_function,\n",
    "                                          batched=True)\n",
    "\n",
    "    # 重命名列\n",
    "    tokenized_datasets = tokenized_datasets.rename_column('label', 'labels')\n",
    "\n",
    "    return tokenized_datasets\n",
    "\n",
    "\n",
    "#-------------------- 模型训练 --------------------#\n",
    "def train_model(bert_path, class_num: int = 3):\n",
    "\n",
    "    # 获取预训练的编码器和模型\n",
    "    tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        bert_path, num_labels=class_num)\n",
    "\n",
    "    # 获得向量化后的数据\n",
    "    tokenized_datasets = tokenize_data(tokenizer)\n",
    "\n",
    "    # 定义评价指标\n",
    "    def compute_metrics(eval_preds):\n",
    "        logits, labels = eval_preds\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            labels, predictions, average='micro')\n",
    "        acc = accuracy_score(labels, predictions)\n",
    "        result = {\n",
    "            'accuracy': acc,\n",
    "            'f1': f1,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        }\n",
    "\n",
    "        return result\n",
    "\n",
    "    #-------------------- 定义训练参数 --------------------#\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=saved_path,  # 保存路径，存放检查点和其他输出文件\n",
    "        evaluation_strategy='steps',  # 每50steps结束后进行评价\n",
    "        eval_steps=50,\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=50,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=50,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\",\n",
    "        report_to=\"tensorboard\",\n",
    "        # warmup_steps=500,  # 热身步数\n",
    "        # weight_decay=0.01,  # 权重衰减\n",
    "        learning_rate=2e-5,  # 初始学习率\n",
    "        per_device_train_batch_size=64,  # 训练批次大小\n",
    "        per_device_eval_batch_size=64,  # 测试批次大小\n",
    "        num_train_epochs=4,  # 训练轮数\n",
    "\n",
    "    )\n",
    "\n",
    "    # 定义训练器\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets[\"dev\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    # 开始训练\n",
    "    trainer.train()\n",
    "\n",
    "    # 训练完成以后的测试集评价\n",
    "    trainer.evaluate(eval_dataset=tokenized_datasets['test'])\n",
    "\n",
    "\n",
    "train_model(model_path, class_num=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.推理任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据保存的模型进行预测\n",
    "Cloud_Saved_Path='/content/gdrive/MyDrive/Saved_Models/FinBERT_L-12_H-768_A-12/checkpoint-350'\n",
    "Local_Saved_Path='/content/LocalSaved/'\n",
    "\n",
    "# 加载云盘的模型到本地\n",
    "def load_saved_model():\n",
    "    if not os.path.exists(Local_Saved_Path):\n",
    "        os.makedirs(Local_Saved_Path)\n",
    "    \n",
    "    import shutil\n",
    "    # 下载模型\n",
    "    try:\n",
    "        shutil.copytree(Cloud_Saved_Path,Local_Saved_Path)\n",
    "    except FileExistsError as e:\n",
    "        pass\n",
    "    \n",
    "load_saved_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
